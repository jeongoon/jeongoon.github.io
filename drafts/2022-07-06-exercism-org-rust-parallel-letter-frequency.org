---
title: Exercism - Rust - Parallel Letter Frequency
description: Introduction to concurrent programming in rust
keywords: rust, parallel, concurrency, channel
author: Myoungjin Jeon
---

** Brief Introductions (not original)

 Count the frequency of letters stored in /a/ list of =&str=. i.e:

#+begin_src rust
pub fn frequency(input: &[&str], worker_count: usize) -> HashMap<char, usize>
#+end_src

 However, we need depoly workers(thread) which is specified as ~worker_count~. This requirement
 makes this task exciting and challenging as I have little exprience on concurrency programming.
 And original introduction also suggest:

 Learn more about concurrency in Rust here: [[https://doc.rust-lang.org/book/ch16-00-concurrency.html][Concurrency]]

 Which actually covers enough knowledge about introduction to concurrency and helps to solve
 this task!

** Working on concurrency
   Breifely, we are using concurrent programming because to get
#+begin_quote
   - Parallel - Do the /similar/ or same job *at the same* time to /save time/.
   - Concurrency - Separate the job because we really need to do several job *at the same time*.
#+end_quote

   The task is about former case. And latter case is related to almost every programming
   related to dynamic I/O.

   Now we should think about how to:

#+begin_quote
   - How to communicate between thread
   - Devide the task properly
#+end_quote

   The first thing is most important here because if we don't know how to communicate each other,
   we could not achieve common goal, counting /whole/ string. So how to talk to each others?

** How To Make Thread and How To Reap them
   Oh, wait, I found that we need to talk about how to make thread(s) and harvest the threads.
   This is the first example on rust documentation

#+begin_src rust
  use std::thread;
  use std::time::Duration;

  fn main() {
      let _handle = thread::spawn(|| {
          for i in 1..10 {
              println!("hi number {} from the spawned thread!", i);
              thread::sleep(Duration::from_millis(1));
          }
          // note: there is no return value here: return value is not essential.
      });

      for i in 1..5 {
          println!("hi number {} from the main thread!", i);
          thread::sleep(Duration::from_millis(1));
      }
#+end_src

  And the result:
#+begin_src sh
hi number 1 from the main thread!
hi number 1 from the spawned thread!
hi number 2 from the main thread!
hi number 2 from the spawned thread!
hi number 3 from the main thread!
hi number 3 from the spawned thread!
hi number 4 from the main thread!
hi number 4 from the spawned thread!
hi number 5 from the spawned thread!
#+end_src
  
** oh, no. we should wait for our friends.

  Does it look good? but if we look carefully. we can find that some output is missing as
  the our spawned thread is supposed to print up to *9*, but we only got 5 here
#+begin_src sh
hi number 5 from the spawned thread!
#+end_src

   This is because main thread reach the end of block before the children thread finished its job.

   We should have waited for our friend threads to see all the output.

#+begin_src rust
// .. snip ..
    for i in 1..5 {
        println!("hi number {} from the main thread!", i);
        thread::sleep(Duration::from_millis(1));
    }

    _handle.join().unwrap(); // wait until for the children thread to join to current thread.
}

#+end_src

*** What join() returns
    - type
    - we can use it for the result of the task as well.

** Communication Between threads in rust

*** return value from thread
    I could see many other's solution using return value from the each thread after
    submitting the my first solution. I found the major pros and -- maybe -- cons:

    - pros: similar approach to normal function call (no extra setup)
    - ??: the main thread is required to choose to which thread the main talks

  The latter sentence could be cons. let's think about worst senario:
#+begin_src rust
  let sample = &["very long string. abcdefghijklmnopqrstuvxyz...",
                 "",
                 "some more text", ];


  // snip ..
  let total = HashMap::new();

  for handle in handles {
      our_counting_fold_fn(total, handle.join().unwrap());
  }
  // snip ..
#+end_src

    So, clearly, the first employee need to work harder than other ðŸ˜‚.
    And we can see if the the diffrence between the lengths of the strings is larger,
    the longer time will be /wasted/ by last two cases and the /main/ thread to wait only for
    first thread to finished the job. /i.e: we lost the chance to summerize other results only to wait for first result./

    So, if the main thread could not figure out how to /choose/ right thread, the performance
    in total isn't great: no benefit from the thread at all.

*** Shared memory
    I found the sentence from the original [[https://doc.rust-lang.org/book/ch16-03-shared-state.html][documentation]].
#+begin_quote
   access the same shared data. Consider this part of the slogan from the
   Go language documentation again: â€œdo not communicate by sharing memory.â€
#+end_quote

   But I found that rust wouldn't say the same thing. but overall, my first impression on
   shared memory in concurrency is:

   - optional
   - less efficient
   - complicated
   - but it is still useuful when requirement of multi ownership comes in.

    So even though, I tried to use in my first try. I'd like to skip this one because:

    - Less over-head is preferred in this simple task.
    - Yet, one thread is enought to summerize the results from others

    Even though, I wouldn't go further, rust ownership is great to dealing with shared-memory
    
#+begin_quote
Management of mutexes can be incredibly tricky to get right, which is why so many people are enthusiastic about channels. However, thanks to Rustâ€™s type system and ownership rules, you canâ€™t get locking and unlocking wrong.
#+end_quote
    Sounds promising, I hope I can go further on this subject later some time.

    By the way, /Mutex is an abbreviation for mutual exclusion/.

** Message Passing via channel
    let's check outh why many people are enthusiastic about message passing.

    [[https://doc.rust-lang.org/book/ch16-02-message-passing.html][The document of message passing(channel)]] starts with the sentence like below:
#+begin_quote
One increasingly popular approach to ensuring safe concurrency is message passing
#+end_quote
    We can safely assume that the message passing as a recommended method for communicating, can't we?

    There is one more thing we need to think about before going further to solve the task

** ownership matters
    The key difference between message passing and shared-memory is the number of ownership.
    and message passing allows only one ownership at a time which gurantees
    the receiver could get the consistent result as it won't be allowed for sender to access
    the value after sending them. It may sounds tedious at first.
    What if the value could be touched after sending them? the answer is:

#+begin_quote
We cannot gurantee the what will happen
#+end_quote

    The unpredictable is most dangerous thing in programming world, nobody would want that
    unless we are throwing a dice.

    I felt that /rust documentation is quite logical/. please read more on [[https://doc.rust-lang.org/book/ch16-02-message-passing.html][The original book]].

**   How to make channel
*** one on one
#+begin_src rust
  use std::sync::mpsc;
  use std::thread;

  fn main() {
      let (tx, rx) = mpsc::channel();

      thread::spawn(move || {
          let val = String::from("hi");
          // sending from the friend thread
          tx.send(val).unwrap();
      }); // return value is not quite useful here so it in void context
          // no `let` statement or no following function(method call) after that.

      // receiving from the main thread
      let received = rx.recv().unwrap();
      println!("Got: {}", received);
  }
#+end_src

*** many speakers and only one listener
    Now I'd like to remind you that we have actually many workers who want to talk about
    their accomplishment with their works.

    But if =tx= variable is moved to one thread, we cannot use it in another thread. This has
    something with the simple principle in rust after all. *ownership*.

    So we need to clone them as much as we need. This process is relatively simple:

#+begin_src rust
  // .. snip ..
  let (tx_main, rx_main) = mpsc::channel();
  let mut handles = vec![];

  // .. snip ..
  (0..worker_count)
      .for_each(|_| {
          let tx = tx_main.clone(); // this is it. simple and easy

          let handle = thread::spawn(move || {
              // now tx is only available in this thread only
              // as its ownership is moved here.
          });
          handles.push(handle);
      });
  // .. snip ..

#+end_src

***  my first collecting the partial results is not working
    The example code in rust shows me how to read from receiver(rx_main).
    But unknown reason make the following code runs infinitely.

#+begin_src rust
      rx_main
          .into_iter()
          .fold(HashMap::new(), |mut acc, partial_acc| {
              partial_acc
                  .iter()
                  .for_each(|(&ch, &count)| match acc.entry(ch) {
                      Occupied(o) => *o.into_mut() += count,
                      Vacant(v) => {
                          v.insert(count);
                      }
                  });
              acc
          })
  }
#+end_src

    So.. I had to drop the code which directly iterating from the receiver,
    I rather go with the following approach:

#+begin_src rust
  // note: the following code works only one main thread.
  (0..worker_count) // use it for only numbering the iteration
      .for_each(|_id| {
          rx_main
              .recv() // like when I did for single read.
              .unwrap()
          //  .somefunc() ... and summerizing(folding) go around here
      });
#+end_src

  I know this is not perfect reading because it only takes one value per thread.
  what if each thread talks more than one?
  /It works so far, I apoligize that if it is not enough explanation. I will come back forthis if I found the reason and workaround for it./

** Dividing the tasks
    It is time to give the threads something to work with. we need to divide our job into
    a certain amount of smaller pieces so that you can hand them over the our workers(threads).

    We'll get the fixed amount of input data, so I decided:

    - Divide the the list into as many as the number of workers and store it into
#+begin_src rust
  // example: &[&str] -> Vec<Vec<String>>  with two workers
  &[ "abc", "def", "ghi", "jkl" ]
     // ->
   vec![
       vec!["abc", "ghi"], // note it is acually going to be String via to_string()
       vec!["def", "jkl"],
   ]
#+end_src

    - /Move/ the each vector to the /one/ appropriate thread.

***  The partial code so far
#+begin_src rust
  pub fn frequency(input: &[&str], worker_count: usize) -> HashMap<char, usize> {
      let num_workers = if worker_count == 0 { 1 } else { worker_count };
      let mut handles = vec![];

      // make a channel for all the results collected
      let (tx_main, rx_main) = mpsc::channel();

      let mut input_per_worker = vec![vec![]; num_workers];
      input
          .iter()
          .zip((0..worker_count).cycle()) // .cycle() easy way to rotating
                                          //  the numbers
          .for_each(|(&s, i)| { // ( string as &str, index(or id) number )
              input_per_worker.get_mut(i) // access the value at the index i`
                  .unwrap() // it is safe to access because we allocate the
                            // memory space already
                  .push(s.to_string()); // required to copy
                                        // to ensure life time inside the thread
          });

      input_per_worker.into_iter().for_each(|input_| {
          // preprare for sending
          let tx = tx_main.clone();
          // prepare for listening
          let handle = thread::spawn(move || {
              // collect count
              let mut subtotal = HashMap::<char, usize>::new();

              input_.iter().for_each(|s| {
                  // snip ..
#+end_src

*** benefits from memory access
    =input_per_worker.get_mut(i)= is a great inheritance from the memory access. In haskell,
    maybe generating with lazy evaluation is better approach for this kind of problem.

** Counting the Alphabets
    This is quite easy task and I didn't make a seprate function for this
#+begin_src rust
  // .. snip ..
  input_per_worker.into_iter().for_each(|input_| {
      // note: .into_iter() used because I want to move the ownership into
      //       the for_each()

      // preprare for sending
      let tx = tx_main.clone();
      // prepare for listening
      let handle = thread::spawn(move || {
          // collect count
          let mut subtotal = HashMap::<char, usize>::new();

          input_.iter().for_each(|s| {
              // input_ is vector string
              // to access the character from string
              // we need to go into first level here (1)
              s.chars().for_each(|ch| {
                  // and go through the character here (2)

                  if ch.is_alphabetic() {
                      // note: this task actually only insensitive on ascii alphabets
                      // speed up 2x when using simple to_ascii_lowercase()
                      // another option is
                      // change s.chars() -> s.to_lowercases().chars()
                      // and use as it is.
                      let lc = ch.to_ascii_lowercase();
                      /*ch.to_lowercase().for_each(|lc|*/

                      // the following pattern was posted in
                      // https://jeongoon.github.io/posts/2022-05-20-exercism-org-raindrops.html#leave-it-as-basic
                      match subtotal.entry(lc) {
                          Occupied(o) => *o.into_mut() += 1,
                          Vacant(v) => {
                              v.insert(1);
                          }
                      } /*);*/
                  };
              })
          });
          // finally sending
          tx.send(subtotal).unwrap();
      });
      handles.push(handle);
  });

#+end_src

*** to_lowercase() or to_ascii_lowercase()
    As I mentioned as a comment, there are some issues with lower case. In short,

    - If you need to apply lower case on whole /unicode/ string: go for [[https://doc.rust-lang.org/std/primitive.str.html#method.to_lowercase][str::to_lowercase]]
    - otherwise use =char::to_ascii_lowercase= or =str::to_ascii_lowercase=.
      
    /I used char::to_ascii_lowercase() because I'd like to filter first (is_alphabetic()), and then apply/

** Finally Summerizing
    fold() could be handy when you are only asked to for the final result. And naturally
    we don't need to worry about ownership and lifetime on the accumulator thanks to nature
    of functional programming. I took the fold() again here.

#+begin_src rust
// .. snip
    handles.iter().fold(HashMap::new(), |mut acc, _handle| {
        rx_main
            .recv()
            .unwrap()
            .iter()
            .for_each(|(&ch, &count)| match acc.entry(ch) {
                Occupied(o) => *o.into_mut() += count,
                Vacant(v) => {
                    v.insert(count);
                }
            });
        acc
    })
} // end of pub fn frequency()
#+end_src

** Brief Benchmark
    This task comes with benchmark code as well and the the following is one of my benchmark
    on 9 years old xps.

#+begin_src sh
    Finished bench [optimized] target(s) in 0.74s
     Running unittests src/lib.rs (target/release/deps/parallel_letter_frequency-016160b8c250f033)

running 0 tests

test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s

     Running benches/benchmark.rs (target/release/deps/benchmark-15a648eb6d4b6f2b)

running 6 tests
test bench_large_parallel   ... bench:     320,958 ns/iter (+/- 102,875)
test bench_large_sequential ... bench:     693,308 ns/iter (+/- 49,224)
test bench_small_parallel   ... bench:      70,801 ns/iter (+/- 3,162)
test bench_small_sequential ... bench:      24,034 ns/iter (+/- 1,025)
test bench_tiny_parallel    ... bench:      61,810 ns/iter (+/- 3,850)
test bench_tiny_sequential  ... bench:          73 ns/iter (+/- 12)

test result: ok. 0 passed; 0 failed; 0 ignored; 6 measured; 0 filtered out; finished in 21.73s
#+end_src

*** parallel is not always helpful _ë³‘ë ¬ì²˜ë¦¬
    Even though first /bench_large_parallel/ shows that benefit from the concurrency, the others
    do not show the benefit at all.

    Because there are some overhead to make thread(s), we should be be careful on applying
    parallel or concurrency

    The bench marking is pretty wise way to learn something to see the what we can earn or
    lose by using some sort of methods.


** Wrapping Up

    This is quite long article, due to the subject. But I'd like to share my thoughts
    on concurrency:

    - Once you making the threads, think about how to reap as well.

    - Communication between the threads is an important factor of concurrency.
      - Message passing
      - Shared memory

    - Use the concurrency wisely
      - benchmarking is important to see the effect objectively
      - Less thread and less ownership makes less overhead
      - but don't be afraid, rust won't compile the thread-/unsafe/ code.
